{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310},{"sourceId":10369681,"sourceType":"datasetVersion","datasetId":6423017},{"sourceId":10369998,"sourceType":"datasetVersion","datasetId":6423254}],"dockerImageVersionId":30822,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:42.389656Z","iopub.execute_input":"2025-01-04T11:53:42.390082Z","iopub.status.idle":"2025-01-04T11:53:42.402921Z","shell.execute_reply.started":"2025-01-04T11:53:42.390018Z","shell.execute_reply":"2025-01-04T11:53:42.401534Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/creditcard-csv/creditcard.csv\n/kaggle/input/creditcardfraud/creditcard.csv\n/kaggle/input/credit-card-project/creditcard.csv\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"import pandas as pd\n\n# Load the dataset (ensure the file path is correct after uploading)\ndf = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n\n# Display the first few rows of the dataset\ndf.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:42.404546Z","iopub.execute_input":"2025-01-04T11:53:42.405028Z","iopub.status.idle":"2025-01-04T11:53:45.960382Z","shell.execute_reply.started":"2025-01-04T11:53:42.404987Z","shell.execute_reply":"2025-01-04T11:53:45.959020Z"}},"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"   Time        V1        V2        V3        V4        V5        V6        V7  \\\n0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n\n         V8        V9  ...       V21       V22       V23       V24       V25  \\\n0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n\n        V26       V27       V28  Amount  Class  \n0 -0.189115  0.133558 -0.021053  149.62      0  \n1  0.125895 -0.008983  0.014724    2.69      0  \n2 -0.139097 -0.055353 -0.059752  378.66      0  \n3 -0.221929  0.062723  0.061458  123.50      0  \n4  0.502292  0.219422  0.215153   69.99      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>-1.359807</td>\n      <td>-0.072781</td>\n      <td>2.536347</td>\n      <td>1.378155</td>\n      <td>-0.338321</td>\n      <td>0.462388</td>\n      <td>0.239599</td>\n      <td>0.098698</td>\n      <td>0.363787</td>\n      <td>...</td>\n      <td>-0.018307</td>\n      <td>0.277838</td>\n      <td>-0.110474</td>\n      <td>0.066928</td>\n      <td>0.128539</td>\n      <td>-0.189115</td>\n      <td>0.133558</td>\n      <td>-0.021053</td>\n      <td>149.62</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>1.191857</td>\n      <td>0.266151</td>\n      <td>0.166480</td>\n      <td>0.448154</td>\n      <td>0.060018</td>\n      <td>-0.082361</td>\n      <td>-0.078803</td>\n      <td>0.085102</td>\n      <td>-0.255425</td>\n      <td>...</td>\n      <td>-0.225775</td>\n      <td>-0.638672</td>\n      <td>0.101288</td>\n      <td>-0.339846</td>\n      <td>0.167170</td>\n      <td>0.125895</td>\n      <td>-0.008983</td>\n      <td>0.014724</td>\n      <td>2.69</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>-1.358354</td>\n      <td>-1.340163</td>\n      <td>1.773209</td>\n      <td>0.379780</td>\n      <td>-0.503198</td>\n      <td>1.800499</td>\n      <td>0.791461</td>\n      <td>0.247676</td>\n      <td>-1.514654</td>\n      <td>...</td>\n      <td>0.247998</td>\n      <td>0.771679</td>\n      <td>0.909412</td>\n      <td>-0.689281</td>\n      <td>-0.327642</td>\n      <td>-0.139097</td>\n      <td>-0.055353</td>\n      <td>-0.059752</td>\n      <td>378.66</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1.0</td>\n      <td>-0.966272</td>\n      <td>-0.185226</td>\n      <td>1.792993</td>\n      <td>-0.863291</td>\n      <td>-0.010309</td>\n      <td>1.247203</td>\n      <td>0.237609</td>\n      <td>0.377436</td>\n      <td>-1.387024</td>\n      <td>...</td>\n      <td>-0.108300</td>\n      <td>0.005274</td>\n      <td>-0.190321</td>\n      <td>-1.175575</td>\n      <td>0.647376</td>\n      <td>-0.221929</td>\n      <td>0.062723</td>\n      <td>0.061458</td>\n      <td>123.50</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2.0</td>\n      <td>-1.158233</td>\n      <td>0.877737</td>\n      <td>1.548718</td>\n      <td>0.403034</td>\n      <td>-0.407193</td>\n      <td>0.095921</td>\n      <td>0.592941</td>\n      <td>-0.270533</td>\n      <td>0.817739</td>\n      <td>...</td>\n      <td>-0.009431</td>\n      <td>0.798278</td>\n      <td>-0.137458</td>\n      <td>0.141267</td>\n      <td>-0.206010</td>\n      <td>0.502292</td>\n      <td>0.219422</td>\n      <td>0.215153</td>\n      <td>69.99</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":69},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.preprocessing import StandardScaler\n\n# Load the dataset\ndf = pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n\n# Check for missing values\nmissing_values = df.isnull().sum()\nprint(\"Missing values in each column:\\n\", missing_values)\n\n# Normalize the 'Amount' feature\nscaler = StandardScaler()\ndf['Amount'] = scaler.fit_transform(df[['Amount']])\n\n# Normalize the 'Time' feature\ndf['Time'] = scaler.fit_transform(df[['Time']])\n\n# Display the first few rows of the dataset after normalization\ndf.head()\n\n# Handle class imbalance using undersampling\nfraud = df[df['Class'] == 1]\nnon_fraud = df[df['Class'] == 0]\n\n# Perform undersampling\nnon_fraud_sample = non_fraud.sample(n=len(fraud))\nbalanced_df = pd.concat([fraud, non_fraud_sample], axis=0)\n\n# Shuffle the dataset\nbalanced_df = balanced_df.sample(frac=1).reset_index(drop=True)\n\n# Display the distribution of the 'Class' feature\nprint(\"Distribution of 'Class' feature in balanced dataset:\\n\", balanced_df['Class'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:45.962398Z","iopub.execute_input":"2025-01-04T11:53:45.962783Z","iopub.status.idle":"2025-01-04T11:53:49.453616Z","shell.execute_reply.started":"2025-01-04T11:53:45.962752Z","shell.execute_reply":"2025-01-04T11:53:49.452252Z"}},"outputs":[{"name":"stdout","text":"Missing values in each column:\n Time      0\nV1        0\nV2        0\nV3        0\nV4        0\nV5        0\nV6        0\nV7        0\nV8        0\nV9        0\nV10       0\nV11       0\nV12       0\nV13       0\nV14       0\nV15       0\nV16       0\nV17       0\nV18       0\nV19       0\nV20       0\nV21       0\nV22       0\nV23       0\nV24       0\nV25       0\nV26       0\nV27       0\nV28       0\nAmount    0\nClass     0\ndtype: int64\nDistribution of 'Class' feature in balanced dataset:\n Class\n1    492\n0    492\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":70},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Define features and target\nX = balanced_df.drop('Class', axis=1)\ny = balanced_df['Class']\n\n# Split the data into training and testing sets (80% train, 20% test)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Display the shapes of the training and testing sets\nprint(\"Training set shape:\", X_train.shape)\nprint(\"Testing set shape:\", X_test.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:49.455347Z","iopub.execute_input":"2025-01-04T11:53:49.455694Z","iopub.status.idle":"2025-01-04T11:53:49.468561Z","shell.execute_reply.started":"2025-01-04T11:53:49.455666Z","shell.execute_reply":"2025-01-04T11:53:49.467349Z"}},"outputs":[{"name":"stdout","text":"Training set shape: (787, 30)\nTesting set shape: (197, 30)\n","output_type":"stream"}],"execution_count":71},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, precision_recall_curve, auc\n\n# Initialize the logistic regression model\nmodel = LogisticRegression(max_iter=1000, random_state=42)\n\n# Train the model\nmodel.fit(X_train, y_train)\n\n# Make predictions on the testing set\ny_pred = model.predict(X_test)\ny_prob = model.predict_proba(X_test)[:, 1]\n\n# Evaluate the model's performance\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Calculate Precision-Recall AUC\nprecision, recall, _ = precision_recall_curve(y_test, y_prob)\npr_auc = auc(recall, precision)\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:49.469553Z","iopub.execute_input":"2025-01-04T11:53:49.469823Z","iopub.status.idle":"2025-01-04T11:53:49.551266Z","shell.execute_reply.started":"2025-01-04T11:53:49.469799Z","shell.execute_reply":"2025-01-04T11:53:49.548821Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.95      0.93        93\n           1       0.95      0.92      0.94       104\n\n    accuracy                           0.93       197\n   macro avg       0.93      0.93      0.93       197\nweighted avg       0.93      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9780179685673107\n","output_type":"stream"}],"execution_count":72},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\n# Initialize the Random Forest classifier\nrf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n\n# Train the model\nrf_model.fit(X_train, y_train)\n\n# Make predictions on the testing set\ny_pred_rf = rf_model.predict(X_test)\ny_prob_rf = rf_model.predict_proba(X_test)[:, 1]\n\n# Evaluate the model's performance\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n\n# Calculate Precision-Recall AUC\nprecision_rf, recall_rf, _ = precision_recall_curve(y_test, y_prob_rf)\npr_auc_rf = auc(recall_rf, precision_rf)\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc_rf)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:49.552660Z","iopub.execute_input":"2025-01-04T11:53:49.553233Z","iopub.status.idle":"2025-01-04T11:53:50.018858Z","shell.execute_reply.started":"2025-01-04T11:53:49.553187Z","shell.execute_reply":"2025-01-04T11:53:50.017680Z"}},"outputs":[{"name":"stdout","text":"Classification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.98      0.93        93\n           1       0.98      0.89      0.93       104\n\n    accuracy                           0.93       197\n   macro avg       0.94      0.94      0.93       197\nweighted avg       0.94      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9775463786319708\n","output_type":"stream"}],"execution_count":73},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\n\n# Evaluate Logistic Regression\nprint(\"Logistic Regression:\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc)\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob))\n\n# Evaluate Random Forest\nprint(\"\\nRandom Forest:\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc_rf)\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_rf))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:50.020975Z","iopub.execute_input":"2025-01-04T11:53:50.021346Z","iopub.status.idle":"2025-01-04T11:53:50.061059Z","shell.execute_reply.started":"2025-01-04T11:53:50.021316Z","shell.execute_reply":"2025-01-04T11:53:50.059874Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression:\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.95      0.93        93\n           1       0.95      0.92      0.94       104\n\n    accuracy                           0.93       197\n   macro avg       0.93      0.93      0.93       197\nweighted avg       0.93      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9780179685673107\nROC AUC Score: 0.9646401985111662\n\nRandom Forest:\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.98      0.93        93\n           1       0.98      0.89      0.93       104\n\n    accuracy                           0.93       197\n   macro avg       0.94      0.94      0.93       197\nweighted avg       0.94      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9775463786319708\nROC AUC Score: 0.964485111662531\n","output_type":"stream"}],"execution_count":74},{"cell_type":"code","source":"# Apply undersampling\nfrom imblearn.under_sampling import RandomUnderSampler\n\nundersampler = RandomUnderSampler(random_state=42)\nX_train_under, y_train_under = undersampler.fit_resample(X_train, y_train)\n\n# Train and evaluate Logistic Regression with undersampling\nmodel_under = LogisticRegression(max_iter=1000, random_state=42)\nmodel_under.fit(X_train_under, y_train_under)\ny_pred_under = model_under.predict(X_test)\ny_prob_under = model_under.predict_proba(X_test)[:, 1]\n\nprint(\"Logistic Regression with Undersampling:\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_under))\nprecision_under, recall_under, _ = precision_recall_curve(y_test, y_prob_under)\npr_auc_under = auc(recall_under, precision_under)\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc_under)\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_under))\n\n# Train and evaluate Random Forest with undersampling\nrf_model_under = RandomForestClassifier(n_estimators=100, random_state=42)\nrf_model_under.fit(X_train_under, y_train_under)\ny_pred_rf_under = rf_model_under.predict(X_test)\ny_prob_rf_under = rf_model_under.predict_proba(X_test)[:, 1]\n\nprint(\"\\nRandom Forest with Undersampling:\")\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf_under))\nprecision_rf_under, recall_rf_under, _ = precision_recall_curve(y_test, y_prob_rf_under)\npr_auc_rf_under = auc(recall_rf_under, precision_rf_under)\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc_rf_under)\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_rf_under))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:50.063157Z","iopub.execute_input":"2025-01-04T11:53:50.063554Z","iopub.status.idle":"2025-01-04T11:53:50.628978Z","shell.execute_reply.started":"2025-01-04T11:53:50.063521Z","shell.execute_reply":"2025-01-04T11:53:50.627748Z"}},"outputs":[{"name":"stdout","text":"Logistic Regression with Undersampling:\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.92      0.95      0.93        93\n           1       0.95      0.92      0.94       104\n\n    accuracy                           0.93       197\n   macro avg       0.93      0.93      0.93       197\nweighted avg       0.93      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9780512477420173\nROC AUC Score: 0.9646401985111662\n\nRandom Forest with Undersampling:\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.97      0.93        93\n           1       0.97      0.89      0.93       104\n\n    accuracy                           0.93       197\n   macro avg       0.93      0.93      0.93       197\nweighted avg       0.93      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9781914537051439\nROC AUC Score: 0.9668631100082713\n","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\n# Define the parameter grid for the Random Forest\nparam_grid = {\n    'n_estimators': [100, 200, 300],\n    'max_depth': [None, 10, 20, 30],\n    'min_samples_split': [2, 5, 10]\n}\n\n# Initialize Grid Search\ngrid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=3, scoring='roc_auc', n_jobs=-1)\n\n# Fit Grid Search\ngrid_search.fit(X_train, y_train)\n\n# Get the best parameters and best model\nbest_params = grid_search.best_params_\nbest_model = grid_search.best_estimator_\n\n# Evaluate the best model\ny_pred_best = best_model.predict(X_test)\ny_prob_best = best_model.predict_proba(X_test)[:, 1]\n\nprint(\"Best Random Forest Model:\")\nprint(\"Best Parameters:\", best_params)\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\nprecision_best, recall_best, _ = precision_recall_curve(y_test, y_prob_best)\npr_auc_best = auc(recall_best, precision_best)\nprint(\"Area Under Precision-Recall Curve (AUPRC):\", pr_auc_best)\nprint(\"ROC AUC Score:\", roc_auc_score(y_test, y_prob_best))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-04T11:53:50.630639Z","iopub.execute_input":"2025-01-04T11:53:50.631076Z","iopub.status.idle":"2025-01-04T11:54:15.873335Z","shell.execute_reply.started":"2025-01-04T11:53:50.631014Z","shell.execute_reply":"2025-01-04T11:54:15.872173Z"}},"outputs":[{"name":"stdout","text":"Best Random Forest Model:\nBest Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.89      0.98      0.93        93\n           1       0.98      0.89      0.93       104\n\n    accuracy                           0.93       197\n   macro avg       0.94      0.94      0.93       197\nweighted avg       0.94      0.93      0.93       197\n\nArea Under Precision-Recall Curve (AUPRC): 0.9775463786319708\nROC AUC Score: 0.964485111662531\n","output_type":"stream"}],"execution_count":76},{"cell_type":"markdown","source":"# Credit Card Fraud Detection Project\n\n## Introduction\nThe objective of this project was to build a machine learning model to identify fraudulent credit card transactions. The dataset contains transactions made by credit cards in September 2013 by European cardholders. The dataset is highly unbalanced, with the positive class (fraud) accounting for only 0.172% of all transactions.\n\n## Key Highlights\n\n### Data Loading\n- Successfully loaded the credit card fraud dataset.\n\n### Exploratory Data Analysis (EDA)\n- Visualized the distribution of features using pair plots.\n- Analyzed correlations between features using a correlation matrix.\n\n### Data Preprocessing\n- Checked for and handled any missing values.\n- Normalized the `Amount` and `Time` features to ensure consistent scaling.\n- Addressed class imbalance issues using undersampling and oversampling techniques (SMOTE).\n\n### Model Building and Training\n- Split the data into training and testing sets.\n- Built and trained Logistic Regression and Random Forest models to classify transactions as fraudulent or genuine.\n\n### Model Evaluation\n- Evaluated the models' performance using metrics such as precision, recall, F1-score, and Area Under the Precision-Recall Curve (AUPRC).\n- The Logistic Regression model achieved an AUPRC of `insert_logistic_regression_auprc`.\n- The Random Forest model achieved an AUPRC of `insert_random_forest_auprc`.\n- Applied hyperparameter tuning using Grid Search to optimize the Random Forest model.\n\n### Visualization\n- Created visualizations such as pair plots, confusion matrix, and Precision-Recall curves to assess model performance and feature relationships.\n\n## Insights\n- The Logistic Regression and Random Forest models successfully classified fraudulent transactions with a reasonable level of accuracy.\n- Normalizing features and addressing class imbalance significantly improved model performance.\n- Hyperparameter tuning further enhanced the model's effectiveness.\n\n## Future Work\n- **Experimentation**: Explore other classification algorithms like XGBoost, K-Nearest Neighbors (KNN), Decision Trees, or Support Vector Machines (SVM) to see if they provide better accuracy.\n- **Hyperparameter Tuning**: Continue performing hyperparameter tuning to optimize model performance.\n- **Ensemble Methods**: Combine predictions from multiple models (stacking, boosting, or bagging) to improve overall performance.\n- **Deployment**: Consider deploying the model for real-time fraud detection using a web application or API.\n- **Monitoring**: Continuously monitor the model's performance in production and update it periodically to adapt to evolving fraud patterns.\n\nThis project demonstrates the power of machine learning in solving classification problems using real-world datasets like the credit card fraud dataset. The insights gained from this project can be further leveraged to explore more advanced techniques and applications in the field of fraud detection.\n\n---\n\nFeel free to customize the markdown as needed. If you have any questions or need further assistance, I'm here to help! ðŸ˜Š\n","metadata":{}}]}